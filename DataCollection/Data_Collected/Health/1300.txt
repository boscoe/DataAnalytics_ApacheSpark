AdvertisementSupported byMending HeartsBy Gina KolataCardiologists recently hailed early results of a study suggesting that many lives might be saved if people with high blood pressure got it down far below levels now recommended. They predicted swift changes in treatment practices.But the intense interest in this big, rigorous clinical trial masked a startling truth about heart research: Many studies are never published, their findings consigned to oblivion.It is an issue that is arising in other parts of medicine as well, but heart disease is one area where it has been especially well documented. Hundreds of millions of dollars has been going to heart studies that are too small and narrow to yield results meaningful enough to get into a journal. In an era of ever-tightening budgets, federal health officials acknowledge that money has been squandered on work that makes no difference to patients or even to research scientists.Now, a few years after coming to that jolting realization, the influential federal agency that funds much of the nation’s heart research is overhauling its practice, a change with far-reaching implications for the way medical research is funded in this country. The result will be the financing of fewer, but deeper, studies, to focus resources on efforts with real-world impact and life-or-death implications.“We are much more willing to turn down proposed trials,” said Dr. Michael Lauer, who is the newly appointed deputy director for extramural research of that agency, the National Institutes of Health. In fact, he added, “we are turning them down.”The pronounced shift is shaking up a field where change is usually measured in tiny increments. Some question this new direction.“If you want to do things that are truly innovative and cutting edge, you sometimes have to do things that are high risk-high gain,” said Dr. Steven A. Webber, a pediatric cardiologist at Vanderbilt, arguing for the need to continue funding small exploratory studies like one he conducted, which he could not complete because of unexpected technical issues.This rethinking of how to study heart disease, which kills more than 600,000 Americans a year, began with an epiphany three years ago: Dr. Lauer and colleagues at the National Heart, Lung and Blood Institute discovered they had spent $2 billion on more than 200 clinical trials over the course of a decade. But the results of two out of five of the studies either were minever made public or were published only after what to scientists were unconscionable delays.“If a research project is never published it is as if it never happened,” Dr. Lauer said.So starting next year, the heart institute will require that all research results be reported in a federal database even if no journal will publish them. In addition to turning down smaller studies, it is insisting that the costs of large studies go way down — even if that means sacrificing data by, for example, not gathering lab results on peripheral questions researchers think are interesting.Though some researchers are unsettled by the new practices, many agree that money was often wasted under the old system. Five small studies cost less than one large one, so the temptation, federal officials acknowledge, has been to stuff the clinical trials portfolio with small studies, especially given the reality of the federal budget. Funds for the National Institutes of Health have fallen by 20 percent in inflation-adjusted dollars since 2006.“It’s worth understanding how perverse — and that’s the right word — the environment has been for clinical trials,” said Dr. Salim Yusuf, a cardiologist at McMaster University in Ontario.Dr. Lauer never expected to uncover such a troubled system when he asked for data on the publication — or nonpublication — of heart institute studies. The results shocked him and his colleagues, and after some soul searching they reported their findings in The New England Journal of Medicine. They realized they were airing what some said was the institute’s dirty laundry in a journal that is all but required reading for medical researchers. “We did it anyway,” Dr. Lauer said, explaining that he could hardly criticize others for not publishing and then fail to publish his own results.Others have also unearthed stunning rates of nonpublication. A Yale study found more than half of studies funded by the National Institutes of Health were not published in the 30 months after they were completed. A group at Duke examining more than 13,000 clinical trials of drugs found most had not reported results by five years after completion, even though the Food and Drug Administration requires reporting by one year after a study’s end. Federally funded studies were less likely to report results than those funded by drug companies.A new Yale study under review at a medical journal found that a failure to publish afflicts researchers equally in prestigious medical centers and ones that are less well known. “If people really knew what was happening they would be outraged,” said Dr. Nihar Desai, a Yale scientist who has been investigating nonpublication.Dr. Lauer’s study found that trials of treatments with obvious life-or-death meaning, like testing a way to cut heart attacks, almost always were published within two years of completion; 70 percent were published a year or less after closing. Negative or equivocal results did not make any difference in publication rates.But trials with so-called surrogate endpoints — Did cholesterol levels rise or fall? Did people walk more each day? — tended to languish.Many small studies focused on understanding biochemical pathways that lead to disease. For example, researchers would conduct what they call feeding trials: participants come to a lab to be fed different diets, with the food prepared in special research kitchens. Investigators then drew the subjects’ blood to see how their blood sugar or cholesterol levels were affected by what they ate.“A feeding trial definitely has value and provides insights,” Dr. Lauer said. “But it has absolutely nothing to do with what happens in the real world.”Another change will come with the design of large trials. The new emphasis will be on so-called pragmatic trials that look for outcomes that matter, like reductions in heart attacks or deaths. Participants in such trials are ordinary people of the sort doctors see every day. They are randomly assigned to one group or another — to take a drug meant to prevent heart disease or to take a placebo, for example.To cut costs, the institute will require researchers to make use of data that are already being collected during routine care, like information on episodes of chest pain or heart attacks.Donald Berry, a statistician at MD Anderson Cancer Center, says there are drawbacks to doing large studies that use clinical data from electronic health records, for example, to cut costs. The result, he said, can be the mingling of clinical trials and clinical practice, which have long been kept separate for ethical reasons. In a clinical trial, the goal is to get data that will help all patients, whereas in clinical practice, the goal is to help each individual patient.Another issue, Dr. Berry said, is the focus on single, simple endpoints. “The patient and the patient’s disease course should be the endpoint,” Dr. Berry said. “It’s not just when you die but how you got there.”But few would argue that trial design cannot be improved.Earlier trials often took years to complete, in part because so many participants were excluded because of age or other medical conditions.Researchers had to do all the lab tests on the participants and gather their own data on patients’ clinical histories. These steps added greatly to the cost of trials, which often reached more than $50 million or even run into hundreds of millions. The new plan is to fund studies for no more than $1.5 million per year, which means a total cost well under $10 million for a typical trial.As for those studies that languish unpublished, researchers will be required to post results on clinicaltrials.gov — whether or not they publish a paper. If the government is going to pay for these studies, said Dr. Francis S. Collins, director of the National Institutes of Health, the public should be able to see the data. And that includes data on all clinical trials, not just ones on heart disease, he added.Those whose studies are not published often say it is not their fault. Rhonda Cooper-DeHoff, for example, an assistant professor of pharmacotherapy and translational research at the University of Florida, tried to publish the results of her study, which she completed in 2009. She wrote a paper and sent it to three journals, all of which summarily rejected it, she said.The study, involving just two dozen people, asked if various high blood pressure drugs worsened sugar metabolism in people at high risk of diabetes.“It was a small study and our hypothesis was not proven,” Dr. Cooper-DeHoff said. “That’s like three strikes against me for publication.” Her only option, she reasoned, would be to turn to an open-access journal that charges authors to publish. “They are superexpensive and accept everything,” she said. Last year she decided to post her results on clinicaltrials.gov.Dr. Lauer called a few investigators who had not published their results and heard a variety of explanations.But excuses do not assuage the harm that is done, Dr. Lauer emphasized, including what he considers an unethical abandonment of participants in those studies.“If you subject a person to the risks and hassles of being in a clinical trial, there is an implicit promise that they are giving to science,” he said. “Giving to science means the results get published.”Advertisement