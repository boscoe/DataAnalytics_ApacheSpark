AdvertisementSupported byBy Neal E. BoudetteThe Obama administration’s approach to hands-free driving is remarkably hands-off.In one of the country’s most heavily regulated industries, the new federal guidelines that are meant to speed the development of self-driving cars give automakers wide latitude. The policy, announced on Tuesday, would generally let the industry decide for itself how to create supersmart automobiles that can navigate roads on their own, whether driving across town or across the country.The one firm requirement: Make sure those cars are safe. Otherwise, federal officials have warned, the government will exercise its right under current regulations to pull them off the road.And yet, the bulk of the new Federal Automated Vehicles Policy is devoted to the goal — produce self-driving cars that prevent accidents and avoid pedestrians and obstacles — without telling automakers how to do it or which technologies to use.The policy is designed to “create a path for a fully autonomous driver with different designs than what we have on the road today,” Mark Rosekind, head of the National Highway Traffic Safety Administration, said at Washington news conference on Tuesday. “If you look at the policy, it provides that path.”Automakers on Tuesday welcomed the hands-off approach.“You can’t get locked into one technology or approach, and it doesn’t seem like they are doing that here,” said Brad Stertz, director of government affairs at Audi of America, the German automaker’s United States arm. “They want to have the flexibility to allow the technology to evolve and evolve in the safest way.”David Strickland, a former administrator of the federal safety agency who is now general counsel for the Self-Driving Coalition for Safer Streets, a group that includes Ford Motor, Google and Uber, said the administration’s policy set a framework that should allow manufacturers to “pull this technology together in an expeditious way.”Despite their multitude of sensors and processors, autonomous cars have a lot of trouble with some everyday aspects of driving.The guidelines, which stop short of formal regulations, have been more than a year in the making.All along the question of safety has hovered over the discussion, particularly as automakers and technology companies have put more test vehicles onto public roads. Google, for example, has logged roughly two million miles of testing with its driverless cars. Uber recently began using a test fleet of autonomous cars for its ride-hailing service in Pittsburgh.More intense scrutiny came this summer after the disclosure that Joshua Brown was killed in Florida when his Tesla Motors car, with its Autopilot system engaged, crashed into a tractor-trailer at highway speed.The Autopilot system, which uses cameras and radar to scan the roadway and can steer Tesla vehicles with little help from the driver, failed to recognize the truck and data showed that neither it nor Mr. Brown hit the brakes before the impact. The National Highway Traffic Safety Administration is investigating the crash to determine if any safety flaws exist in the Autopilot mode.The accident put a spotlight on semiautonomous systems that can take over many of the driving duties but require human drivers to remain alert and ready to take control at a moment’s notice. As soon as this week, Tesla is expected to download new software onto its vehicles that will include improvements to Autopilot.Anthony Foxx, secretary of the United States Department of Transportation, said at a news conference on Tuesday that the new guidelines were not aimed at Tesla, and were being developed well before that fatal accident.And yet, several parts of the 116-page policy, address safety issues highlighted by the Tesla crash.Semiautonomous driving systems, the policy says, must take into account the fact that distracted or inattentive drivers may fail to retake control, and the systems could be considered “an unreasonable risk to safety and subject to recall.”After Joshua Brown, 40, of Canton, Ohio, was killed driving a Tesla Model S in the first fatality involving a self-driving car, questions have arisen about the safety of the car’s technology.Mike Ramsey, a research director at Gartner Group who focuses on auto technology, said the Transportation Department probably did not add such statements because of the Tesla accident. But the language “clearly affects” the company, he said.“Other companies are rolling out Autopilot-like systems, so it’s not just Tesla they’re talking about,” he said.Tesla says Autopilot is not meant to be a fully autonomous driving system, although YouTube videos have shown some owners driving with no hands on the steering wheel and performing other stunts while the system is active. Tesla cars warn drivers to keep their hands on the wheel and eyes on the road while using Autopilot. The company has said the new version will be even stricter in that regard.Tesla said on Tuesday that it was not ready to comment on the new federal guidelines.Whether the guidelines will become formal policy is uncertain. Automakers and any other interested parties have 60 days to comment to the Transportation Department, a period that will not end until after the presidential election on Nov. 8. A new administration could modify, rework or scrap the guidelines.But the policy received strong backing from auto safety advocates, who pointed out that more than 34,000 people died in auto-related accidents in 2015.“Autonomous technology and especially driverless cars can absolutely be game-changers,” Colleen Sheehy-Church, the national president of Mothers Against Drunk Driving, said on Tuesday. “Autonomous vehicles could potentially stop most traffic deaths in our country.”The push for autonomous vehicles is also supported by those who see self-driving cars as a new means of transportation for the disabled, the elderly and others who are unable to drive.Eric A. Taub contributed reporting.Advertisement