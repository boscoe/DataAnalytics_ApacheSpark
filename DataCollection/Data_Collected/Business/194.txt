AdvertisementSupported byBy Eduardo PorterIn my reporting for my column this week, I had an email exchange with Bruce Tonn, who led the team at Oak Ridge National Laboratory that performed an analysis of the federal weatherization program. Public affairs officers at Oak Ridge and the Department of Energy, as well as the panel of experts who advised Oak Ridge’s researchers, reviewed the exchange. Following is a version of the exchange, slightly compressed and edited for clarity.Q. Why did you remove the costs of administration, training, etc., from your estimate of the costs of the weatherization program? Shouldn’t a cost/benefit analysis of weatherization include all these costs?A. The Weatherization Assistance Program (WAP) is not a simple energy program. It has multiple stakeholders, including state and local weatherization agencies, utilities, home occupants, public health officials, advocacy groups, taxpayers and others, and produces energy and nonenergy benefits.A committee composed of stakeholders from across the national weatherization network was convened back in 2005 to provide direction to those of us responsible for crafting the evaluation plan. The various reports contain information that is useful to these multiple interested parties. The peer-review panel we convened in 2006 to provide comment on our draft evaluation plan recommended that we incorporate health benefits into our calculations regarding the value of the program.Different stakeholders benefit from different estimates of cost effectiveness. For many years, the cost effectiveness of energy programs has been measured and reported in several ways. For example, the local weatherization agencies are primarily interested in the cost effectiveness of weatherization jobs.To provide the most information to the Department of Energy and WAP stakeholders, these ratios are broken out by housing type, fuel type and climate zone. Ratios of energy savings to costs excluding administration and other costs are useful for comparing across measures, say to better focus programs on the most cost effective homes or fuels or climate zones or programs that encompass different sets of measures. As you note, all of the costs are not included and neither are all of the benefits in these Savings-to-Investment Ratios.Programwide ratios do include all the costs and so should also include all the benefits. The WAP evaluation reports lay out the total costs, which include leveraged funds from sources outside the Department of Energy that could impact cost effectiveness. The evaluation also endeavored to estimate/monetize a set of nonenergy benefits because the more easily estimated costs do not reflect the broader cost effectiveness of the program. Estimating the value of the nonenergy impacts of energy efficiency programs in general and weatherization specifically has a long history. It should be noted that the evaluation did not monetize all of the potential nonenergy benefits of weatherization.Q. It seems to me that the mortality calculations rely on some fairly speculative assumptions. They seem to be reached by projecting responses from your survey about whether people sought medical help onto national estimates about what share of people seeking medical help die.A. Perhaps it would be beneficial to expound on how the results are presented in tiers. The tier designations represent the varying degrees of rigor and inherent uncertainty in our efforts to monetize benefits. The levels of uncertainty were characterized utilizing several criteria. These criteria included, to name a few, whether there is a strong, well-recognized logical link; whether the phenomenon is directly observable; the sample size is representative; and there are few or no confounding factors. The models utilized to monetize many nonenergy benefits were deemed to have low levels of uncertainty and therefore are confidently categorized as Tier 1. (Note: see table E.S.1)The presence or absence of mortality estimates didn’t have a bearing on the tier in which benefits fell. We disagree strongly with the assertion that we used “fairly speculative assumptions” in arriving at these estimates. With respect to thermal stress, for example, the existing research and data prove that people die from exposure to extreme temperatures in their homes. To establish rates of deaths following hospitalizations, with the primary diagnosis being exposure to extreme temperatures, we utilized a medical database that is the largest collection of nationwide longitudinal hospital care data in the U.S. These databases are derived from administrative data and contain encounter-level, clinical and nonclinical information, including all-listed diagnoses and charges for all patients. We applied the same proportion of fatalities following hospitalization for the population served by WAP. It’s actually a conservative estimate, because this population is at higher risk than the general population. We also calculated, using the same databases, the proportion of types of treatment sought for heat- and cold-related illnesses; therefore, we believe that the rates of hospitalization, emergency department and physician office visits following exposure to extreme temperatures are accurate and representative.We chose to include this data in our model because it was not practical to attempt to estimate the actual number who died of thermal stress pre- or post-weatherization. People who die from such exposure often live alone and therefore we would not expect to receive a survey response. We believe that our approach is reasonable and establishes the potential of the WAP program to reduce medical treatment and fatalities. Weatherization has been shown to increase comfort within the home, reduce the rates of homes being kept at an unsafe temperature, and reduce the rate of those seeking medical treatment. A future research project could collect death certificates, energy billing histories and other data that could help estimate the number of people whose deaths from thermal stress might have been prevented by weatherization, but that was beyond the scope of this evaluation.Q. I don’t understand your methodology. Usually, the impacts of a program are assessed comparing changes recorded in the “treatment” sample of the population, who received the program, with changes in a comparable “control” sample that did not. But you do not have a control sample of homes that were not weatherized.A. Through the WAP evaluation we were able for the first time to conduct a national survey of a representative sample of weatherized households. To build the sample for the treatment group, approximately 200 randomly selected local weatherization agencies sent lists of homes in the queue to receive energy audits in the short term. Then treatment group homes for the survey were randomly selected from the pool of all these homes. These homes were surveyed just before they received their audits and again post-weatherization about 18 months later.Because of legal and ethical issues, it was not possible to divide these homes randomly into groups that would get their audits and be weatherized in the short term and homes that would have both their audits and weatherization delayed by a year or more. So we had to find another approach to developing a sample for the control group.Theoretically, we could have gone back in time like we did with the energy bills and assembled a sample of homes that ultimately received weatherization services. The survey would have asked respondents about behaviors several years ago at two different points in time. Because of the memory issue concerns with this approach, this approach was quickly discarded.For another approach, we could have developed sampling frames from lists of all low-income homes in the jurisdiction of each local weatherization agency in our sample, or lists of homes that receive assistance to pay their energy bills. Doing this would have been cost prohibitive at the very least. Also, WAP homes are different from the typical low-income home and the typical recipient of energy assistance because the WAP homes consume more energy. Also, not all WAP homes receive energy assistance. So it was decided that the comparison group would be homes that were weatherized the previous year. This sample is reasonable because they are WAP homes and feasible because the local weatherization agencies were able to provide lists from which the comparison homes were randomly selected.Q. The calculations on which you base your analysis are also unusual. The standard “difference in differences” formula to assess, say, health changes from weatherization would be written like:Impact of weatherization = (health of treatment group in Period 1, before weatherization – health of treatment group in Period 2, after weatherization) – (health in non-weatherized control group in Period 1 – health in control group in Period 2)But rather than measuring the difference between changes in each group, you take the average of two unrelated changes:Impact of weatherization = [(health of treatment group in Period 1 – health of treatment group in Period 2) + (health of treatment group in Period 1 – health in Period 1 of another group whose homes had been weatherized the year before]/2A. We were unable to do a classic differences of differences estimate because we did not have a comparison group that was surveyed two times without already being weatherized. Our comparison group was surveyed one year after it was weatherized, at the same time as the treatment group before it was weatherized, and the comparison group was surveyed again two years post-weatherization at the same time the treatment group was surveyed after weatherization.The method described in the report takes the approach that we have two estimates of the impact of the intervention. We have (Pre-treatment – Post-treatment) and we also have (Pre-treatment – Comparison group one year post). Let’s use some hypothetical numbers:Pre-treatment = 10% (hospitalizations in the past year, say)Post-treatment = 8%Comparison one year post = 7%Using the numbers above, the estimates of the intervention are 10-8=2% and 10-7=3%, respectively. The method simply averages these two estimates to arrive at 2.5%.Q. Some of your estimates do not appear to be statistically different from zero, and yet you still seem to use them in your final analysis of benefits. (see, for instance, Footnote 91 on Page 82 of the report linked above.) That raises a question about the statistical robustness of the entire enterprise.A. As we discussed, specific approaches were developed to monetize each of the benefits addressed in the health benefits report. The estimates produced by these techniques are not subject to statistical tests. However, to convey uncertainties about the estimates, the monetized results are presented in tiers depending on the strengths of the underlying data and other criteria, per the recommendation of the peer review panel.In developing our analyses, we did face the issue of whether our sample sizes were large enough to capture rare events. For example, our survey did ask questions about fires and carbon monoxide poisoning before and after weatherization. The responses indicated that both were very rare given our sample size and national data supports these conclusions. However, we believe that preventing fires and CO poisoning are important, so it would be worthwhile to estimate the monetized benefits of reducing fires and CO poisoning given that deaths could be prevented. In these two instances we relied upon data collected by the evaluation on the measures installed (e.g., CO monitors, various measures that map to fire ignition risks) in weatherized homes to anchor our methodologies.Had the sample size been larger, or had the study oversampled in very cold weather or a hot-humid climate zone, and possibly included large multifamily units, one could argue that findings for thermal stress would be even higher. But we believe that the magnitude of the change in medical needs from before to after weatherization is of public interest. So in this situation we felt it was ethical to push on with our analyses using the survey results and our expert review panel did not have an issue with our approach. Consider that this high-risk population will only become at higher risk as temperatures rise and the frequency and duration of heat waves continue to increase due to climate change.Consider asthma. Hospitalizations for asthma are rare events within the general population, which is where the analysis began. Emergency department visits are less rare and were observed more often in the treatment group before weatherization. The improvement in asthma morbidity as measured by emergency department visits in the asthma sample was determined to be statistically significant. Although a reduction in hospitalizations for asthma was observed after weatherization, it was not statistically different from zero. We believe this to be a result of a small sample size and a rare event. So it was determined by the peer-review that costs should be included in the monetization of reductions in asthma-related hospitalizations for these reasons. Regression and correlation analyses were also conducted.These observations are substantiated by anecdotal evidence from the human stories shared by the community action agencies and by the beneficiaries of the programs. These stories guided this component of the evaluation. They offered the evaluation team its Question Zero: How can we measure the health and household-related benefits attributable to WAP that are shared by the network and the families served?The stakeholders of WAP are numerous and diverse and some don’t even realize they are beneficiaries of WAP, like the public health community, for instance. Ultimately, the evaluation team analyzed the benefits from multiple angles and determined that ancillary benefits not related to energy savings were not being fully recognized. We documented recipients’ experiences to better understand the target population and its needs; determined whether the benefit was a logical benefit of weatherization; and used the literature and experience to guide our methodology. In some cases, such as asthma, special studies were designed to gather additional data, like Medicaid claims and costs. Triangulation — arriving at conclusions by using multiple sources of information — is a common research method within the social sciences. Doing it this way we were able to incorporate reported changes into the larger monetized benefit even if they did not achieve statistical significance.Q. Your analysis of health benefits did not incorporate data you collected from an indoor air quality study. It finds no impact from weatherization on carbon monoxide levels and increased levels of radon and formaldehyde. Why didn’t you use this?A. We have several responses to this question. First, as stated on Page 59 of the health benefits report, the analyses focus on potential benefits that are almost immediately accruable. For example, weatherization immediately reduces asthma triggers. The report does not address longer term nonenergy impacts, so other topics such as the potential beneficial impacts related to reducing cardiac heart disease are not addressed in our study. Specifically, with respect to radon, the literature indicates that it may take many years before exposure to radon could result in a health impact.In a review of a draft of the indoor air quality report, the Environmental Protection Agency did identify the radon result as a point to discuss with the Department of Energy but did not make note of formaldehyde. As a result the Department of Energy and the E.P.A. are engaged in policy discussions regarding radon. It should be noted that there has been a discussion about how to regard the radon measurements from our study because the short-term measurements were taken in the winter, under closed-home conditions, and before new weatherization and ventilation standards were put in place. The Department of Energy is supporting further study on this topic.Q. Finally, it seems that you made no effort to make sure your samples of treatment and comparison homes are indeed comparable, to ensure that your findings are not driven by some unacknowledged difference between the populations.A. Various tables in another report show that the treatment group before weatherization and the comparison group one year after weatherization are comparable across demographic variables. Here is an aggregated table of selected variables:Other tables indicate that the homes are structurally the same — for instance, the same share of homes have attics and garages — have the same sets of appliances, and energy behaviors.In summary, we are confident that the treatment group before weatherization and the comparison group one year after weatherization are similar.Advertisement