AdvertisementSupported byBy Noam ScheiberWASHINGTON — Each July, many of the top economists in the world gather in Cambridge, Mass., at a conference hosted by the National Bureau of Economic Research. While the work they present comes in all shapes and sizes, from the highly technical to the trendy and provocative, the coveted first day of a key weeklong session is given over to research that will make a media splash.“I choose the papers,” said David Card, a prominent labor economist at the University of California, Berkeley. “I choose papers that are going to be written up” in the mainstream press.Professor Card explained that the elders of the field recognized the growing importance of media visibility, and he felt obliged to give it to them. “It’s what the people want,” he said.In the days since revelations first appeared that a Ph.D. candidate at U.C.L.A. may have misrepresented data in a study about gay-marriage advocacy — which received coverage in outlets like The New York Times, Vox.com and “This American Life” — many social scientists have observed that their disciplines, which once regarded the ability to attract attention with suspicion, increasingly reward it. It has not gone unnoticed that Michael LaCour, the study’s author, was en route to an assistant professorship at Princeton. (On Friday, a day after the journal Science retracted the study, which it published in December, Mr. LaCour admitted lying about some aspects, but said he stood by the study’s results.)Few would dispute that the scholars, their advisers and the journal editors who vet their work bear chief responsibility for flawed research. And, in any case, those who go so far as to commit outright fraud are rarely motivated by the prospect of publicity alone.Still, the benefits to academics of generating media attention may be subtly skewing their research. “The pressure is tremendous,” said James Heckman, an economist at the University of Chicago and the winner of a Nobel Memorial Prize in Economic Science. “Many young economists realize that they win a MacArthur or the Clark prize, or both, by being featured in The Times.”Most hiring committees and tenure review boards in the social sciences continue to give more weight to publications or the potential to publish in top technical journals above other factors when making decisions that affect the careers of young academics.But popular media attention increasingly works in a candidate’s favor as well. For tenure decisions, “I’ve gotten letters,” Dr. Heckman said, “that ask me to assess the impact and visibility of a person’s work.”Often the effect is indirect but no less pronounced. Many scholars said, for example, that a growing number of colleagues relied on nonprofit foundations to finance their research and that foundation administrators tended to be most excited when the work found its way into the news media.“The grant-giver looks at this and says, ‘O.K., let’s fund this guy or this woman because we’re not just going to generate results that are read by 10 people,’ ” said Daniel Drezner, a political scientist at Tufts University’s Fletcher School of Law and Diplomacy. “It’s actually going to be talked about.”The foundation grant can help pay for the collection of exotic data, of the kind that Mr. LaCour claimed to have procured, which has a higher likelihood of yielding groundbreaking results.All of this has led to a new model of disseminating social science research through the media. Several economists at top departments said colleagues were now tailoring and pitching their academic papers to journalists, rather than writing papers and allowing the news media to discover them on their own.One danger is that many journalists are not equipped to distinguish good science from shoddy science. That is a particular risk when the work does not wend its way through the usual academic channels before entering the news media’s consciousness.“If it appears in the papers before it’s peer-reviewed, that can be a problem,” said Gary King, a Harvard political scientist.While the top journals in political science or economics typically spend six months to a year or more reviewing and revising submissions, the same review process is considerably shorter at a general interest journal like Science, where Mr. LaCour published his findings. Science tends to take less than two months, according to Ginger Pinholster, a spokeswoman for the journal.The retraction by Science of a study of changing attitudes on gay marriage is the latest in a growing number of prominent withdrawals of the results of studies from scientific literature.“Often it’s one and a half years between the time a paper is submitted and the time a paper is accepted,” said Professor Card, referring to the top economics journals. “Much of that time is spent with extremely long and excruciating responses to the referees and the editors.”The process at Science, some scholars say, can even encourage authors to inflate the significance of their work. “The reviewer will say, ‘The result is real, the conclusion is reasonable, but it doesn’t really say something that would interest a general audience,’ ” said Dr. Narayanan Kasthuri, a medical researcher soon to be at Argonne National Laboratory, who has published in Science. “That means, ‘Go back and make the conclusion broader, more spectacular.’ ”On the other side of the equation, publishing in a more technical journal can be so time-consuming that it often delays work well beyond the time it would be of interest to the public. “It’s good to have academic research grounding the conversation with more empiricism,” said Ezra Klein, the editor of Vox.com.Many scholars believe that the peer-review process at Science is sound. “I felt the referees were pretty scrupulous,” Dr. Heckman said. “They seemed to know what they were talking about.”But the process appears at least partly to reflect the journal’s goal of bringing more visibility to the work it publishes.“One of the things the American Association for the Advancement of Science”— the journal’s publisher — “is big on is wanting to communicate science, to keep the public interested,” Monica Bradford, the executive editor, said. For example, three to four people on the association’s digital media team work to drive traffic to articles in its publications through the social media.As the competition for faculty positions and research funding intensified in recent decades, scientists came under escalating pressure to publish blockbuster results in a few prominent journals — among them, Science, Nature and Cell.Dr. Ferric Fang, a medical researcher at the University of Washington who has documented rising instances of fraud in scientific papers, said the searches his department conducts for assistant professors typically attract more than 100 applicants. Though many of the applicants for the last half-dozen of those positions have numerous papers in rigorously vetted but less-well-known outlets like the Journal of Bacteriology, nearly all of the finalists have been the lead author of a paper in one of the prominent journals. “You try to battle against it, look at the work itself,” Dr. Fang said. “But the luster of that publication is so strong.”For years, doing social science work with the aim of attracting media attention was regarded as the domain of dilettantes who did not aspire to careful research.After the financial crisis, however, the public and the news media became more interested in serious research, and scholars responded by seeking more coverage. News organizations like The Times and The Washington Post have added special sections, and online outlets like Vox.com have emerged to more thoroughly cover work that grapples with vexing public policy problems including poverty, social mobility and wage stagnation.“Most of the time, in most people’s hands, it’s nothing but a good thing,” said Seema Jayachandran, a visiting professor at the Massachusetts Institute of Technology. “It’s more attention for more important results.”Journalists and scholars are uncovering errors as social scientists share more data and as novel findings draw more interest.Nonetheless, a system that encourages academics to distribute their research through the mainstream media can wreak havoc before errors come to light.In early 2010, for example, the economists Kenneth Rogoff and Carmen Reinhart circulated a non-peer-reviewed paper which showed that countries risked a large dropoff in economic growth once their debt exceeded 90 percent of their gross domestic product. The authors took to the news media to promote  their findings, which politicians in Europe and the United States cited as a rationale for their austerity policies.In 2013, a group of researchers at the University of Massachusetts, Amherst, pointed out a numerical mistake and two questionable practices that cast doubt on the paper’s key finding.Professor Rogoff, in a response to criticism later that year, conceded that the paper contained a minor coding error. But, he added, he and two co-authors had eliminated the error by the time they published a 2012 journal article, “which is much longer and more complete.”He said in an email message that he did not think peer review would have caught the error.Advertisement