

 James Gorman
 

SCIENCETAKE
OCT. 26, 2015
Computer scientists have a way to manipulate videos to change a person’s facial expressions in real time.Moviegoers and electronic game players have grown accustomed to digital manipulation of all sorts of still and moving images.But even the most jaded among them might be surprised by a process that computer scientists in California and Germany have developed to instantaneously transfer facial expressions.With the new technique, one person’s smile appears seamlessly on live video of another person’s face, even though the second person is not smiling at all.A computer processes the transfer in 30 milliseconds, no time at all for a human observer, although less expensive cameras can result in a bit of a lag.AdvertisementThe researchers demonstrate their technique with simultaneous live video from two people, and the result is at least mildly disturbing. Presentations that show unadulterated videos of two people along with the manipulated ones prompt the viewer to keep looking from real to unreal, feeling that something is just not right.AdvertisementMatthias Niessner, a visiting assistant professor at Stanford University who works on the rendering of three-dimensional surfaces in computer graphics, refers to the process as “live facial re-enactment.”Dr. Niessner, along with Justus Thies, a graduate student at the University of Erlangen-Nuremberg, where Dr. Niessner studied, and other colleagues at Stanford and in Germany used the kind of camera that captures gestures in three dimensions, as in the Microsoft Kinect.Please verify you're not a robot by clicking the box.Invalid email address. Please re-enter.You must select a newsletter to subscribe to.View all New York Times newsletters.Software that they developed maps every pixel on both faces, and then transfers the expression. The speed of the process comes partly because the software runs on a number of computer processors at once.Dr. Niessner said he envisioned the technique’s being used to improve dubbing in movies, to make video in virtual reality more realistic, and to provide instantaneous translation.Skype has already released a preview of nearly real-time voice translation during video calls. Dr. Niessner said that with further work, real-time transfer of facial expressions could be combined with real-time translation. Then, for example, if an English speaker were talking to a Mandarin speaker, each would appear to be speaking the other’s language.Dr. Niessner said that when programs like Photoshop first appeared, there was some concern about the dangers of altering visual reality. But now, he said, “The whole advertisement industry is kind of living on Photoshop.” The public has adjusted, and there are techniques to detect any surreptitious alteration of an image. The same would be true with facial re-enactment, he said.The researchers are scheduled to present their work at Siggraph Asia 2015 in Kobe, Japan, next week. Their paper will then be published in the proceedings of the conference, a special issue of ACM Transactions on Graphics.Once the technique becomes popular, it’s reasonable to expect that talking animal videos will become more popular than ever.An earlier version of this article misstated the given name of one of the researchers. He is Justus Thies, not Justin.We’re interested in your feedback on this page. Tell us what you think.See More »