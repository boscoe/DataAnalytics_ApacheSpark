By FARHAD MANJOO, MIKE ISAAC and JOHN MARKOFFMARCH 12, 2016
Each Saturday, Farhad Manjoo and Mike Isaac, technology reporters at The New York Times, review the week’s news, offering analysis and maybe a joke or two about the most important developments in the tech industry. This week, they needed extra help and roped in veteran tech reporter John Markoff.Farhad: Hi, Mike! I’m about to leave for the South by Southwest tech and music festival down in Austin, Tex. I know cool kids like you love to hate on things like SXSW, but I’m superexcited — where else can I enjoy barbecue while watching some yahoos try to break the world record for the largest number of people dressed in banana costumes?Mike: Hello, Farhad! While you have fun, I hurt my back a few weeks ago, so I’m spending my nights creating a Rube Goldbergian bedroom setup to put myself in traction. I may actually be doing myself more harm than good, but I’m insured by The Times, so I’m not too worried about it.Farhad: Oh, that reminds me — at SXSW I’ll be trying out a $4,000 desk that lets you lie down while working. I’m sure our bosses will see that as a reasonable medical expense for you.AdvertisementMike: That sounds good. Please order me two.So, about this week’s news. In the never-ending Apple versus the government battle, the Obama administration rebuked Apple in a filing, and Apple snapped back. It’s getting more tense by the day.AdvertisementSquare reported its first quarterly earnings since it went public in November. Everyone expected it to go poorly, and surprisingly, it didn’t.Farhad: That reminds me of my philosophy in life: underpromise, and then when you barely meet expectations, you’re golden. Wait — isn’t that your philosophy, too?Mike: Yes. How do you think I got this job?Also, General Motors really, really wants to get into the driverless car game in a big way. That’s why the company reportedly bought a driverless car tech start-up for more than $1 billion. Not a bad exit for a start-up that was last valued at less than one-tenth of that amount.And you wrote something on Amazon’s strange, Hal 9000-like personal assistant, Alexa. I didn’t read it, but I’d bet you liked the gadget because it’s a future-facing toy that currently accomplishes very few practical tasks in the present. You identify with that, right?Farhad: I’m going to have Alexa hunt you down, Mike.Speaking of artificial intelligence, I wanted to chat about the big news this week — AlphaGo, a Google computer program that plays the board game Go, beat one of the world’s top human players in the first two games of a five-game series.As you probably don’t know, computers have been beating human chess players for years, but Go has long been something of a holy grail for machines. After years of work, though, DeepMind, a Google subsidiary based in London, showed that a computer program could play Go at a level that was deemed “perfect” by Lee Se-dol, the poor human Go champion who embarrassed humankind by losing to a mere machine.The Bits newsletter will keep you updated on the latest from Silicon Valley and the technology industry.Please verify you're not a robot by clicking the box.Invalid email address. Please re-enter.You must select a newsletter to subscribe to.View all New York Times newsletters.Mike, from what I know, you can barely play checkers. So I thought for this week we’d bring in an expert — our colleague John Markoff, who covers machine intelligence.AdvertisementMike: I’m really good at solitaire.Farhad: John, thanks for joining us! So, how big a deal is this win? I’m most interested in what it tells us about artificial intelligence generally — does the ability to win Go mean that computers can do lots of other things we used to think only humans could do?Also, just for the record, I’m pretty sure I can take AlphaGo in Candyland.John: When I got on a plane this morning, AlphaGo was up 2-0 against Mr. Lee, the South Korean World Go champion. The program’s mastery is impressive, and, after losing for the second time, Mr. Lee said he thought the program had played a perfect game. The program is a blend of deep learning and Monte Carlo algorithms, meaning it is both good at recognizing patterns and has the ability to exhaustively search vast libraries of possible moves.What appears to be happening is the timetable for computing dominance of Go has been moved up roughly a decade from when it had been expected. That’s largely because the new ability to blend pattern recognition algorithms and vast data sets has been yielding spectacular results in the last half-decade. It’s like computer scientists have found a powerful new hammer, and they’re using it to pound lots of different nails.Mike: Wow. I understood the hammer part, but most of that went beyond me. Usually the word “Go” makes me want to collect $200 from Rich Uncle Pennybags.So help me out, John. I read your article on the first match our friend Mr. Lee lost to the evil computer genius, and something struck me: He said part of playing Go takes a certain amount of “human intuition” to do well. Over time, Go players develop a style or personality and approach.I have no idea how this game works, except from what I see of the guys playing against each other in, like, Washington Square Park.But it made me think of playing poker. Part of what makes a person good at a card game — in my case, a hand of No Limit Texas Hold ‘em — is the instinct of the player, developed over time. I may read an opponent, for instance, and bluff them, or trap them, or something. In theory, I am better because of my ability to play my opponents psychologically instead of sticking solely to the logic of how good or bad my cards are.One would think that Mr. Lee has a similar advantage. But I imagine a computer program — even a fancy one from Google — would lack this certain set of skills. Is there something here I’m not getting?AdvertisementJohn: I think we might be talking about a slightly different kind of intuition. The Google program combines two types of algorithms. One is a machine learning algorithm, which does an extremely good job of recognizing patterns based on being trained on a vast set of examples. So it is likely to have seen almost any move that a human could make, and also know which responses are better ones.A second type of algorithm can also see the consequences of particular moves far, far in advance of the game by playing millions and millions or perhaps even billions of combinations of moves. In contrast, human Go experts have their experience to rely on, but it is fuzzy by comparison. Think of this as an intellectual version of John Henry and the jackhammer. And remember, right now the only thing the program can do is play Go.Mike: Wowie woo! I recall John Henry ended up winning in the end! Also I think after winning he immediately collapsed and died. So, there’s that.Thanks for the guest spot, John! I love learning new things.Farhad: Huh. I’d never have guessed that. Seriously. Bye!We’re interested in your feedback on this page. Tell us what you think.See More »