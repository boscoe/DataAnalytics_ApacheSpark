AdvertisementSupported byBitsBy Quentin HardyComputers really are becoming like people: Just because they are smart doesn’t mean they won’t do awful things.As John Markoff writes, the kind of artificial intelligence that is capable of winning at the game of Go or figuring out your fastest route home is also starting to show up in criminal schemes. One program, known as Blackshades, was sold in the online criminal underground known as the dark web and used for purposes like video and audio eavesdropping.The man who developed Blackshades was sentenced in June 2015 to 57 months in prison. As with most other crimes, though, the threat of hard time isn’t going to stop everyone — particularly as the costs keep coming down and the number of applications is exploding.The way A.I. can now recognize text and images, even imitate voices, lends itself to malicious uses in defeating online security, spotting victims, even eventually fooling people into thinking that a machine they’re talking to is a person.It happened to me yesterday. Working from home, I received a robocall to see if I wanted to buy solar panels (a common enough scam). A voice that called itself Amanda started the pitch with a chatty informality that was far superior to a standard recording, though it was still halting and tentative.When I asked if this was a computer, there was a pause, then a stilted “Yes, I’m a real person,” followed by a too-fast pitch that didn’t stop when it was interrupted. Then Amanda hung up on me.I have a feeling she’ll be back, with a faster processor and a better grasp of informal speech.They say one of the best ways to check, for now, is to ask the suspected bot to recite a limerick or sing “Happy Birthday.” It may not be dignified, but it beats being ripped off.Advertisement