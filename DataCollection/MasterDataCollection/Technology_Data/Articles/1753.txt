AdvertisementSupported byBy Mike IsaacSAN FRANCISCO — Since 2005, Reddit has been a veritable wonderland for the most extreme forms of free speech on the Internet.On this general interest message board, all it takes to make — or break — someone else’s day on Reddit is a fleeting thought, a made-up screen name and a few quick keystrokes.But with the site’s pseudonymity have come other byproducts. Some of Reddit’s biggest detractors claim the web discussion forum is a breeding ground for trolls, a hub that helps them organize and spread like a virus across the rest of the Internet.Reddit has in recent months started to address online abuse, and on Wednesday it took one of its bigger steps toward helping individuals gain some control over tormentors: The company said it would give people a blocking feature to shield themselves against harassment on the site, moving to prohibit abusive users from sending messages to others.The blocking feature will build on the concept that the less exposed to negative speech users are on Reddit, the more they will want to engage with the community. That is important for the company, based in San Francisco, which aims to spread far beyond the 243 million unique monthly visitors it currently serves and break into the mainstream consciousness, much like a Facebook or a Twitter — with a similar ability to command online advertising.The blocking tool could also serve to curtail the spread of online abuse beyond Reddit’s walls. Vitriol on the site can sometimes erupt into larger memes, spilling over into social media and other avenues and creating further repercussions. That behavior is also stoked by other digital haunts that are the favorite of trolls, including sites like 4chan and 8chan.Reddit’s influence goes far, said Anil Dash, a web entrepreneur who has worked on blogging platforms like Livejournal. A post on Reddit is “similar to one tweet, embedded anywhere, and how it can travel very long distances,” he said.Others have less faith in Reddit’s ability to clamp down on the Internet’s noxious elements, especially given the amount of time it took the company to take on abuse in the first place. Reddit has long been home to racist, misogynistic subcultures in areas called subreddits — small, topic-based forums where users can discuss whatever they wish. In autumn 2014, Reddit users traded stolen nude photos of celebrities like baseball cards, all organized in a subreddit.“When you’re just now addressing the easiest solutions, it doesn’t speak well for what Reddit’s priorities are,” said Brianna Wu, head of development at Giant Spacekat, a gaming studio. Ms. Wu, who describes herself “a frequent target of the kind of abuse they are trying to stop,” was the recipient of many threats in 2014 because of comments she made about women in the video game industry.Reddit’s creation of the blocking tool, which is available to all registered users, has not gone over well with all of its user base. When the site was founded in 2005 by Steve Huffman and Alexis Ohanian, college dorm mates from the University of Virginia, it took a laissez-faire approach to Internet commentary. The philosophy was to let forum members post almost anything they wanted and let the rest sort itself out.As a result, any restrictions are considered an affront to the open aspects of community dialogue. On Wednesday, five hours after announcing the blocking tool, there were more than 2,300 comments in response to the feature. Some praised the move while others criticized it.“The outcome then will be many subreddits where groupthink will dominate, and discussion will be suppressed,” wrote Donnadre, a Reddit user, in a post on the site discussing the new feature.In an interview, Mr. Ohanian acknowledged that shifting the site away from some of its roots is hard. “People, generally, do not like change,” he said. “We have to do what is best for Reddit over all.”The company has maintained that the number of nastier subreddits is minuscule among the tens of thousands of other subforums devoted to things like makeup, television shows or food.The idea for the blocking tool is similar to a “muting” function used by Twitter, the 320 million-user social network that also faces criticism for the way it handles online abuse. When you block a user on Reddit, you will no longer see that person’s responses to your posts. That person will not know about the block, a strategy aimed at keeping them from simply creating another user account.Some Reddit employees attribute the creation of the new tool to an infusion of resources, including dozens of new employees and more than $50 million in venture capital raised in October 2014. Last May, the company instituted a policy that forbade harassment on the site. Then in July, Mr. Huffman became chief executive of the company in a management shake-up.Shortly after his return, Mr. Huffman told The New York Times that Reddit “cannot turn a blind eye” toward vulgar online behavior. He quickly enforced a set of new content rules that explicitly banned posting content that “violated a common sense of decency,” and encouraged people to report harassment to community moderators.“For a very long time it was all we could do to just keep the site up,” said Chris Slowe, one of Reddit’s first hires and the engineer who worked on the blocking tool. Mr. Slowe said he would like to see Reddit get closer to building automated systems that detect abuse across the site, though he did not give a timeline for such technology.“Now we’re finally at a point where we’ve been growing the team and can deal with things like fundamental product problems such as this,” Mr. Slowe said.Advertisement