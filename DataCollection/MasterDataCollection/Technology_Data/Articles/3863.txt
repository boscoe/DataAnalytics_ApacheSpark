
Bits By                     
 JIM KERSTETTER
 
NOV. 29, 2016
It has not been a banner month for Facebook’s moral compass.First, the company faced blunt accusations that it turned a blind eye to fake news being shared on its service. It didn’t help that Mark Zuckerberg, Facebook’s chief executive, infuriated critics when he publicly doubted that fake news had much effect on the recent presidential election.A few days later, Mr. Zuckerberg, sounding a bit chastened, wrote a post saying the company was looking into ways to deal with the problem.Then The Times’s Mike Isaac reported that Facebook, long shut out of China because of the country’s strict publishing restrictions, was working on a tool that would help the Chinese authorities censor posts.While all that has been going on, the company has also been scrapping with the German authorities over hate speech. Local Jewish institutions and Israeli-owned businesses were included in a map published to Facebook under the banner “Jews Among Us,” in bright yellow Gothic script.AdvertisementEven after people complained, Mark Scott and Melissa Eddy write, Facebook said the map complied with the company’s “community standards.” But German law is far less forgiving of hate speech than an internet company’s community standards, so the map was eventually taken down, along with the far-right page of the group that posted it.AdvertisementIn short: Facebook has difficulty controlling fake news and thinks twice about restricting hate speech, but it will consider giving government censors a way to restrict free speech if it means breaking into a really big market.For years, it has seemed as though Facebook could do no wrong — at least from a business standpoint. But ethics have often been a blind spot, whether it was intrusive user tracking or reluctance to take responsibility for what was posted on the service.Will the controversy of the last month result in a philosophical reckoning? If Facebook’s executives continue to insist that it is not a media company but a tech company with minimal responsibility for the content shared by its users, the simple answer is most likely “no.”We’re interested in your feedback on this page. Tell us what you think.See More »