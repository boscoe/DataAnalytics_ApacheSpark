By SAPNA MAHESHWARI and MIKE ISAACSEPT. 20, 2017
Responding to evidence that its tools had allowed ads to be directed at users who used racist comments or hate speech in their profiles, Facebook said Wednesday that it would change how ads can be targeted.That its ad-targeting tools could be used in such a way was “a fail” for the company, Sheryl Sandberg, Facebook’s chief operating officer, said in a post. She added that Facebook would add “more human review and oversight” to its automated systems to prevent further misuse.Ms. Sandberg, who was directly addressing the social network’s recent advertising issues for the first time, also said the company would do more to ensure that offensive content — including that which attacks people for their race or religion — could not be used to target ads.The announcement came after a report from ProPublica last week revealed that Facebook’s online ad tools had allowed advertisers to target self-described “Jew haters” or people who had used terms like “how to burn Jews.” The terms automatically appeared in Facebook’s ad system because people had apparently filled them in under “education” and “employer” on their profiles.Advertisement“Hate has no place on Facebook — and as a Jew, as a mother, and as a human being, I know the damage that can come from hate,” Ms. Sandberg wrote. “The fact that hateful terms were even offered as options was totally inappropriate and a fail on our part.”AdvertisementMs. Sandberg said the company “never intended or anticipated this functionality being used this way — and that is on us.”Facebook has grown into one of the world’s most valuable companies by offering advertisers the ability to quickly and easily target its users based on a vast array of information, from the type of home they live in to their favorite television shows. But the company is facing a new wave of scrutiny over how those tools can be misused, particularly after it disclosed this month that fake accounts based in Russia had purchased more than $100,000 worth of ads on divisive issues in the run-up to the presidential election.The site has also been criticized for not anticipating that its technology could be put to nefarious use.“The appearance of these offensive terms was embarrassing for Facebook and reflects the tendency of Silicon Valley companies to overly trust algorithms and automated systems to manage advertising,” said Ari Paparo, chief executive of Beeswax, an advertising technology start-up in New York. “The media business is all about people and influence, so there’s a necessary role for human moderation and control.”Please verify you're not a robot by clicking the box.Invalid email address. Please re-enter.You must select a newsletter to subscribe to.View all New York Times newsletters.This is not the first time that Facebook has faced issues stemming from a lack of human oversight. Earlier this year, after a series of violent acts appeared on Facebook Live broadcasts, the company said it would add 3,000 people to the 4,500-member team of employees that reviews and removes content that violates its community guidelines.But this was the first time that Ms. Sandberg, who is responsible for Facebook’s entire advertising organization, has directly addressed the company’s high-profile ad issues in public. Ms. Sandberg, a veteran of the digital advertising industry, grew to acclaim in Silicon Valley by developing Google’s sales organization in the search giant’s early days. She joined Facebook in 2008, and was asked to do the same for the social network.Facebook has faced thorny questions about race and its ad-targeting tools before. Last fall, ProPublica reported that advertisers could use those tools to exclude certain races — or what the social network called “ethnic affinities” — from housing and employment ads, a potential violation of the Fair Housing Act of 1968 and the Civil Rights Act of 1964. Facebook, which assigns the updated term “multicultural affinity” to certain users based on their interests and activities on the site, no longer allows that classification to be used in ads for housing, employment or credit.“A whole bunch of problems have come up for Facebook over the past year that are going to have consequences,” said Brian Wieser, an analyst at Pivotal Research Group who closely follows Facebook. “It’s something between sloppiness, an absence of consideration on a range of issues, and the simple challenges of managing a massive company growing at an unparalleled pace.”AdvertisementFacebook’s annual revenue, nearly all of which comes from online ads, has more than tripled in the past four years to $27.6 billion in 2016, when it posted a net profit of $10.2 billion. Separately, the company has also been working to repair its relationship with major advertisers after it disclosed about a year ago that some of its measurement tools were not delivering accurate results.Facebook, which restricted how advertisers could target users after the publication of last week’s report by ProPublica, reinstated 5,000 of its most commonly used targeting terms, like “nurse” and “teacher,” after manually reviewing the options, Ms. Sandberg said in her post.Ms. Sandberg also said that the company was working on a program to encourage Facebook users to report abuses of its ad system.“The move to add more human reviews is a good one and hopefully they can get ahead of the next issue that might arise in their powerful system,” Mr. Paparo said.A version of this article appears in print on September 21, 2017, on Page B1 of the New York edition with the headline: Facebook Vows More Human Oversight of Ad Targeting.  Order Reprints| Today's Paper|Subscribe

We’re interested in your feedback on this page. Tell us what you think.